{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /opt/conda/lib/python3.8/site-packages (5.0.0)\n",
      "Requirement already satisfied: pygraphviz in /opt/conda/lib/python3.8/site-packages (1.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from rdflib) (1.15.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.8/site-packages (from rdflib) (2.4.7)\n",
      "Requirement already satisfied: isodate in /opt/conda/lib/python3.8/site-packages (from rdflib) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "#import time\n",
      "#import torchvision\n",
      "\n",
      "#var1 = time.dosomething()\n",
      "#var2 = torchvision.doit()\n",
      "var3 = pd.start()\n",
      "var2 = 2\n",
      "data = readfile(\"filename.csv\")\n",
      "#output = var1 + var2 + var3\n",
      "\n",
      "output = var3 + var2 + data\n",
      "\n",
      "print(output)\n",
      "digraph { \n",
      "\"pandas\" -> \"simple-notebook\" [label = \"importedBy\"]\n",
      "\"pd(0)\" -> \"simple-notebook\" [label = \"appearsIn\"]\n",
      "\"pd(0)\" -> \"pandas\" [label = \"assignedFrom\"]\n",
      "\"var3(0)$0\" -> \"pd(0)\" [label = \"start\"]\n",
      "\"2(0)\" -> \"simple-notebook\" [label = \"appearsIn\"]\n",
      "\"var2(0)$0\" -> \"2(0)\" [label = \"assignedFrom\"]\n",
      "\"filename.csv(0)\" -> \"simple-notebook\" [label = \"appearsIn\"]\n",
      "\"data(0)$0\" -> \"filename.csv(0)\" [label = \"readfile\"]\n",
      "\"output(0)$0\" -> \"var3(0)$0\" [label = \"Add\"]\n",
      "\"output(0)$0\" -> \"var2(0)$0\" [label = \"Add\"]\n",
      "\"output(0)$0\" -> \"data(0)$0\" [label = \"Add\"]\n",
      "\"print[0]\" -> \"output(0)$0\" [label = \"print\"]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping start type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import datajourney as DJ\n",
    "f=\"simple-notebook.py\"\n",
    "src = open(f, \"r\").read()\n",
    "print(src)\n",
    "# Generate digraph from source\n",
    "collector = DJ.FindDependencies(f[:-3])\n",
    "collector.collect(src)\n",
    "gs = collector.getStringCollected()\n",
    "print(gs)\n",
    "o = open( f[:-2] + \"digraph\", \"w\")\n",
    "o.write(gs)\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dj: <http://purl.org/dj/> .\n",
      "@prefix k: <http://purl.org/dj/kaggle/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#249561878> rdfs:label \"print[0]\" ;\n",
      "    dj:print <http://purl.org/dj/kaggle/simple-notebook#425460615> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#234619473> rdfs:label \"var2(0)$0\" ;\n",
      "    dj:assignedFrom <http://purl.org/dj/kaggle/simple-notebook#30212276> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#235012690> rdfs:label \"var3(0)$0\" ;\n",
      "    dj:start <http://purl.org/dj/kaggle/simple-notebook#80085334> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#243401328> rdfs:label \"data(0)$0\" ;\n",
      "    dj:readfile <http://purl.org/dj/kaggle/simple-notebook#774636861> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#30212276> rdfs:label \"2(0)\" ;\n",
      "    dj:appearsIn k:simple-notebook .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#425460615> rdfs:label \"output(0)$0\" ;\n",
      "    dj:Add <http://purl.org/dj/kaggle/simple-notebook#234619473>,\n",
      "        <http://purl.org/dj/kaggle/simple-notebook#235012690>,\n",
      "        <http://purl.org/dj/kaggle/simple-notebook#243401328> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#774636861> rdfs:label \"filename.csv(0)\" ;\n",
      "    dj:appearsIn k:simple-notebook .\n",
      "\n",
      "<http://purl.org/dj/kaggle/simple-notebook#80085334> rdfs:label \"pd(0)\" ;\n",
      "    dj:appearsIn k:simple-notebook ;\n",
      "    dj:assignedFrom <http://purl.org/dj/python/lib/144966264> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/144966264> rdfs:label \"pandas\" ;\n",
      "    dj:importedBy k:simple-notebook .\n",
      "\n",
      "k:simple-notebook a k:Notebook ;\n",
      "    rdfs:label \"simple-notebook\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Read digraph \n",
    "g = ag.read_dot( f[:-2] + \"digraph\")\n",
    "\n",
    "\n",
    "# # Generate RDF\n",
    "ns = f[:-3]\n",
    "rdfg = DJ.toRDF(ns, g)\n",
    "s=rdfg.serialize(format=\"turtle\").decode(\"utf-8\")\n",
    "\n",
    "o = open( f[:-2] + \"ttl\", \"w\")\n",
    "o.write(s)\n",
    "o.close()\n",
    "\n",
    "# Read and print ttl\n",
    "o = open( f[:-2] + \"ttl\", \"r\" )\n",
    "print(o.read())\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/simple-notebook.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from graphviz import Source\n",
    "src = Source(gs)\n",
    "src.format = \"png\"\n",
    "src.render(\"images/\" + f[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ieee-gb-2-make-amount-useful-again-Copy1.digraph\n",
      "read dot\n",
      "ERROR Exception: decoding to str: need a bytes-like object, NoneType found [ieee-gb-2-make-amount-useful-again-Copy1.digraph]\n",
      "1  are broken\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import datajourney as DJ\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag\n",
    "import pygraphviz\n",
    "\n",
    "indir = \"./sources/\"\n",
    "graphsdir = \"./test/\"\n",
    "\n",
    "# Test noebooks with errors\n",
    "n = 'ieee-gb-2-make-amount-useful-again-Copy1.digraph' # digraphs broken when '%' in node name\n",
    "\n",
    "graph_files = [n]\n",
    "rdf_all_graph = rdflib.Graph()\n",
    "broken=[]\n",
    "for f in graph_files:\n",
    "    with open(graphsdir + f) as notebook:\n",
    "        print(\"Processing: {0}\".format(f))\n",
    "        try:\n",
    "            print('read dot')\n",
    "            stri = \" \".join([l for l in notebook]) \n",
    "            stri.replace\n",
    "            g = ag.from_agraph(pygraphviz.AGraph(stri))\n",
    "            print('done')\n",
    "            n = f[:-7]\n",
    "            rdfg = DJ.toRDF2(n[:-1], g)\n",
    "            rdf_all_graph = rdf_all_graph + rdfg\n",
    "        except Exception as err:\n",
    "            print(\"ERROR Exception: {0} [{1}]\".format(err, f))\n",
    "            broken.append(f)\n",
    "# Remove broken digraph files from the input\n",
    "print(str(len(broken)), \" are broken\")\n",
    "graph_files = [f for f in graph_files if f not in broken]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: [1, 2, '\\\\%Y - \\\\%M - \\\\%S']\n",
      "edges: [(1, 2), ('\\\\%Y - \\\\%M - \\\\%S', 2)]\n",
      "b'strict digraph \"\" {\\n\\tgraph [bb=\"0,0,224.04,123\"];\\n\\tnode [label=\"\\\\N\"];\\n\\t1\\t[height=0.5,\\n\\t\\tpos=\"27,105\",\\n\\t\\twidth=0.75];\\n\\t2\\t[height=0.5,\\n\\t\\tpos=\"87,18\",\\n\\t\\twidth=0.75];\\n\\t1 -> 2\\t[label=import,\\n\\t\\tlp=\"85.5,61.5\",\\n\\t\\tpos=\"e,76.065,34.491 38.005,88.41 46.97,75.709 59.78,57.562 70.053,43.008\"];\\n\\t\"\\\\%Y - \\\\%M - \\\\%S\"\\t[height=0.5,\\n\\t\\tpos=\"148,105\",\\n\\t\\twidth=2.1123];\\n\\t\"\\\\%Y - \\\\%M - \\\\%S\" -> 2\\t[label=import,\\n\\t\\tlp=\"148.5,61.5\",\\n\\t\\tpos=\"e,99.029,34.183 136.91,87.16 130.38,77.38 121.88,64.88 114,54 111.24,50.192 108.25,46.201 105.31,42.334\"];\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "# Build a digraph manually\n",
    "import networkx as nx\n",
    "dg = nx.DiGraph()\n",
    "dg.add_edge(1, 2, label=\"import\")\n",
    "dg.add_edge(\"\\%Y - \\%M - \\%S\", 2, label=\"import\")\n",
    "print(\"nodes:\", str(dg.nodes))\n",
    "print(\"edges:\", str(dg.edges))\n",
    "ag.write_dot(dg, outdir + \"___percent.\" + \"digraph\")\n",
    "tag = ag.to_agraph(dg)\n",
    "tag.layout(prog='dot')\n",
    "stri = tag.draw(format='dot')\n",
    "print(stri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: graph has 1070 nodes...layout may take a long time.\n",
      "Warning: graph has 7673 nodes...layout may take a long time.\n",
      "Warning: graph has 1504 nodes...layout may take a long time.\n",
      "Warning: graph has 5273 nodes...layout may take a long time.\n",
      "Warning: graph has 5432 nodes...layout may take a long time.\n",
      "Warning: graph has 1233 nodes...layout may take a long time.\n",
      "Warning: graph has 1568 nodes...layout may take a long time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Test the DiGraph method\n",
    "\n",
    "#!/usr/local/bin/python3.7\n",
    "import datajourney as DJ\n",
    "import json as J\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from graphviz import Source\n",
    "import pygraphviz\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag\n",
    "\n",
    "outdir=\"test/\"\n",
    "imgdir=\"images/\"\n",
    "indir=\"sources/\"\n",
    "\n",
    "f=\"ieee-gb-2-make-amount-useful-again.py\"\n",
    "files = [\n",
    "    \"1st-place-reproduction-10feats-dev\",\n",
    "\"a-beginner-guide-for-sale-data-prediction\",\n",
    "\"a-complete-ml-pipeline-fast-ai\",\n",
    "\"a-detailed-regression-guide-with-house-pricing\",\n",
    "\"a-quick-simple-eda\",\n",
    "\"a-visual-and-insightful-journey-donorschoose\",\n",
    "\"airbnb-the-amsterdam-story-with-interactive-maps\",\n",
    "\"all-that-you-need-to-know-about-the-android-market\",\n",
    "\"almost-complete-feature-engineering-ieee-data\",\n",
    "\"an-interactive-deep-dive-into-survey-results\",\n",
    "\"analyzing-soccer-player-faces\",\n",
    "\"aptos-eye-preprocessing-in-diabetic-retinopathy\",\n",
    "\"ashrae-divide-and-conquer\",\n",
    "\"ashrae-energy-prediction-using-stratified-kfold\",\n",
    "\"ashrae-great-energy-predictor-iii-eda-model\",\n",
    "\"ashrae-half-and-half\",\n",
    "\"ashrae-kfold-lightgbm-without-leak-1-08\",\n",
    "\"ashrae-stacked-regression-lasso-ridge-lgbm\",\n",
    "\"automated-feature-engineering-basics\",\n",
    "\"baseline-u-net-model-part-1\",\n",
    "\"beginner-s-tutorial-python\",\n",
    "\"benchmark\",\n",
    "\"bert-and-bidaf\",\n",
    "\"bert-the-spam-detector-that-uses-just-10-words\",\n",
    "\"bird-eye-view-of-two-sigma-nn-approach\",\n",
    "\"black-friday-data-exploration\",\n",
    "\"bond-calculaltion-lb-0-82\",\n",
    "\"bond-calculation-lb-0-82\",\n",
    "\"breaking-lb-fresh-start\",\n",
    "\"breastcancer\",\n",
    "\"brute-force-feature-engineering\",\n",
    "\"cannabis-species-eda-and-models-pipeline\",\n",
    "\"careervillage-org-recommendation-engine\",\n",
    "\"cis-fraud-detection-visualize-feature-engineering\",\n",
    "\"cleaning-up-market-data-errors-and-stock-splits\",\n",
    "\"comprehensive-python-and-d3-js-favorita-analytics\",\n",
    "\"cp2410-assignment1-ryanwong\",\n",
    "\"credit-fraud-dealing-with-imbalanced-datasets\",\n",
    "\"creditcard-fraud-analysis\",\n",
    "\"data-cleaning-challenge-parsing-dates\",\n",
    "\"data-mining-project\",\n",
    "\"data-preparation-exploration\",\n",
    "\"dataset-preprocessing\",\n",
    "\"decision-boundaries-visualised-via-python-plotly\",\n",
    "\"dog-breed-pretrained-keras-models-lb-0-3\",\n",
    "\"ds-bowl-start-here-a-gentle-introduction\",\n",
    "\"dynamics-of-new-york-city-animation\",\n",
    "\"eachtype\",\n",
    "\"eda-and-models\",\n",
    "\"eda-ensemble-model-top-10-percentile\",\n",
    "\"eda-feat-engineering-encode-conquer\",\n",
    "\"eda-understanding-the-dataset-with-3d-plots\",\n",
    "\"eda-weird-images-with-new-updates\",\n",
    "\"efficientnetb5-with-keras-aptos-2019\",\n",
    "\"elo-eda-and-models\",\n",
    "\"end-to-end-project-with-python\",\n",
    "\"exploration-to-quench-chennai-s-thirst\",\n",
    "\"exploratory-analysis-and-predictions\",\n",
    "\"exploratory-study-on-feature-selection\",\n",
    "\"exploratory-study-on-ml-algorithms\",\n",
    "\"extensive-usa-youtube-eda\",\n",
    "\"fake-detect-basic\",\n",
    "\"fast-pdf-calculation-with-correlation-matrix\",\n",
    "\"feature-ranking-rfe-random-forest-linear-models\",\n",
    "\"feature-selection-and-data-visualization\",\n",
    "\"fraud-complete-eda\",\n",
    "\"how-to-get-upvotes-for-a-kernel-on-kaggle\",\n",
    "\"how-to-preprocessing-for-glove-part1-eda\",\n",
    "\"how-top-lb-got-their-score-use-titanic-to-learn\",\n",
    "\"humpback-whale-id-data-and-aug-exploration\",\n",
    "\"ieee-cv-options\",\n",
    "\"ieee-fe-with-some-eda\",\n",
    "\"ieee-gb-2-make-amount-useful-again\",\n",
    "\"ieee-lgbm-with-groupkfold-cv\",\n",
    "\"ieee-transaction-columns-reference\",\n",
    "\"imdb-review-deep-model-94-89-accuracy\",\n",
    "\"improve-your-score-with-some-text-preprocessing\",\n",
    "\"improve-your-score-with-text-preprocessing-v2\",\n",
    "\"insightful-eda-modeling-lgbm-hyperopt\",\n",
    "\"instacart-simple-data-exploration\",\n",
    "\"interactive-d3-js-visualisations-in-kaggle-kernels\",\n",
    "\"introduction-to-feature-selection\",\n",
    "\"introduction-to-manual-feature-engineering\",\n",
    "\"introduction-to-manual-feature-engineering-p2\",\n",
    "\"jiazhen-to-armamut-via-gurchetan1000-0-56\",\n",
    "\"kannada-mnist\",\n",
    "\"keras-nn-with-embeddings-for-cat-features-1-15\",\n",
    "\"keras-unet-with-eda\",\n",
    "\"light-gbm-with-complete-eda\",\n",
    "\"lstm-sentiment-analysis-keras\",\n",
    "\"mask-rcnn-detailed-starter-code\",\n",
    "\"model-stacking-feature-engineering-and-eda\",\n",
    "\"molecular-properties-eda-and-models\",\n",
    "\"more-text-cleaning-to-increase-word-coverage\",\n",
    "\"neural-network-with-mae-objective-0-01381\",\n",
    "\"ny-stock-price-prediction-rnn-lstm-gru\",\n",
    "\"nyct-from-a-to-z-with-xgboost-tutorial\",\n",
    "\"psychology-of-a-professional-athlete\",\n",
    "\"public-version-text-cleaning-vocab-65\",\n",
    "\"python-target-encoding-for-categorical-features\",\n",
    "\"quickdraw-baseline-lstm-reading-and-submission\",\n",
    "\"recommender-systems-in-python-101\",\n",
    "\"reducing-dataframe-memory-size-by-65\",\n",
    "\"reducing-memory-size-for-ieee\",\n",
    "\"road-to-viz-expert-1-unusual-tools\",\n",
    "\"rsna-ih-detection-eda\",\n",
    "\"russia-usa-india-and-other-countries\",\n",
    "\"s-p-500-time-series-forecasting-with-prophet\",\n",
    "\"santa-finances-a-closer-look-at-the-costs\",\n",
    "\"santander-customer-transaction-eda\",\n",
    "\"santander-lightgbm-baseline-lb-0-899\",\n",
    "\"save-the-energy-for-the-future-3-predictions\",\n",
    "\"sign-language-mnist\",\n",
    "\"simple-eda-text-preprocessing-jigsaw\",\n",
    "\"simple-exploration-notebook-ashrae\",\n",
    "\"simple-exploratory-data-analysis-passnyc\",\n",
    "\"simple-lgbm-solution\",\n",
    "\"simple-lstm-pytorch-version\",\n",
    "\"simple-lstm-with-identity-parameters-fastai\",\n",
    "\"simple-neural-net-for-time-series-classification\",\n",
    "\"simple-tutorial-for-beginners\",\n",
    "\"spending-for-ms-in-data-science-worth-it\",\n",
    "\"spooky-nlp-and-topic-modelling-tutorial\",\n",
    "\"stacking-house-prices-walkthrough-to-top-5\",\n",
    "\"strategy-evaluation-what-helps-and-by-how-much\",\n",
    "\"ted-data-analysis\",\n",
    "\"the-hitchhiker-s-guide-to-the-kaggle\",\n",
    "\"the-perfect-score-script\",\n",
    "\"time-series-analysis\",\n",
    "\"time-series-basics-exploring-traditional-ts\",\n",
    "\"titanic-random-forest-82-78\",\n",
    "\"titanic-tutorial\",\n",
    "\"top-3-nlp-libraries-tutorial-nltk-spacy-gensim\",\n",
    "\"topic-7-unsupervised-learning-pca-and-clustering\",\n",
    "\"training-mask-r-cnn-to-be-a-fashionista-lb-0-07\",\n",
    "\"transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\",\n",
    "\"two-sigma-renthop-eda\",\n",
    "\"u-net-model-with-submission\",\n",
    "\"uncover-target-correlations-with-bernoulli-mixture\",\n",
    "\"unet-starter-kernel-pytorch-lb-0-88\",\n",
    "\"unet-with-resnet34-encoder-pytorch\",\n",
    "\"user-data-exploration\",\n",
    "\"using-meta-features-to-improve-model\",\n",
    "\"validation-feature-selection-interpretation-etc\",\n",
    "\"where-do-the-robots-drive\",\n",
    "\"winning-solutions-of-kaggle-competitions\",\n",
    "\"yet-another-deepfake-starter\"\n",
    "]\n",
    "for f in  files:\n",
    "    src = open(indir + f + \".py\", \"r\").read()\n",
    "    # print(src)\n",
    "    collector = DJ.FindDependencies(f[:-3])\n",
    "    collector.collect(src)\n",
    "    # Method 1\n",
    "    dg = collector.getDiGraph()\n",
    "    ag.write_dot(dg, outdir + f[:-3] + \"._1_\" + \".digraph\")\n",
    "    \n",
    "    # Method 2\n",
    "    stri = collector.getStringCollected()\n",
    "    o = open(outdir + f[:-3] + \"._2_\" + \".digraph\", \"w\")\n",
    "    o.write(stri)\n",
    "    \n",
    "    # Method Old\n",
    "    stri = collector.getStringCollected_Old()\n",
    "    o = open(outdir + f[:-3] + \"._0_\" + \".digraph\", \"w\")\n",
    "    o.write(stri)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

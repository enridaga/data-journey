digraph { 
"pyspark.sql" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"SparkSession" -> "pyspark.sql" [label = "importedBy"]
"SparkSession(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"SparkSession(0)" -> "SparkSession" [label = "assignedFrom"]
"pyspark.sql.functions" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"F(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"F(0)" -> "pyspark.sql.functions" [label = "assignedFrom"]
"pyspark.sql.types" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"*" -> "pyspark.sql.types" [label = "importedBy"]
"*(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"*(0)" -> "*" [label = "assignedFrom"]
"spark(0)$0" -> "SparkSession(0)" [label = "getOrCreate"]
"pyspark.sql.functions" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"udf" -> "pyspark.sql.functions" [label = "importedBy"]
"udf(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"udf(0)" -> "udf" [label = "assignedFrom"]
"df(0)$0" -> "spark(0)$0" [label = "csv"]
"df(0)$1" -> "df(0)$0" [label = "show"]
"df(0)$2" -> "df(0)$1" [label = "withColumnRenamed"]
"df(0)$3" -> "df(0)$2" [label = "withColumnRenamed"]
"df(0)$4" -> "df(0)$3" [label = "withColumnRenamed"]
"df(0)$5" -> "df(0)$4" [label = "withColumnRenamed"]
"df(0)$6" -> "df(0)$5" [label = "show"]
"df(0)$7" -> "df(0)$6" [label = "show"]
"df(0)$8" -> "df(0)$7" [label = "show"]
"df(0)$9" -> "df(0)$8" [label = "show"]
"df(0)$10" -> "df(0)$9" [label = "show"]
"df(0)$11" -> "df(0)$10" [label = "show"]
"df(0)$12" -> "df(0)$11" [label = "show"]
"df(0)$13" -> "df(0)$12" [label = "show"]
"df(0)$14" -> "df(0)$13" [label = "show"]
"df(0)$15" -> "df(0)$14" [label = "show"]
"df(0)$16" -> "df(0)$15" [label = "show"]
"df(0)$17" -> "df(0)$16" [label = "show"]
"df(0)$18" -> "df(0)$17" [label = "show"]
"df(0)$19" -> "df(0)$18" [label = "show"]
"df(0)$20" -> "df(0)$19" [label = "show"]
"df(0)$21" -> "df(0)$20" [label = "show"]
"Total_Profit(1)" -> "Prof[0]" [label = "_argToVar"]
"Prof(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"Prof_udf(0)$0" -> "Prof(0)" [label = "udf"]
"StringType(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"Prof_udf(0)$0" -> "StringType(0)" [label = "udf"]
"df(0)$22" -> "df(0)$21" [label = "withColumn"]
"df(0)$22" -> "Prof_udf(0)$0" [label = "withColumn"]
"df(0)$22" -> "df(0)$22" [label = "withColumn"]
"df(0)$23" -> "df(0)$22" [label = "show"]
"df(0)$24" -> "df(0)$23" [label = "show"]
"df1(0)$0" -> "spark(0)$0" [label = "csv"]
"df1(0)$1" -> "df1(0)$0" [label = "show"]
"join_df(0)$0" -> "df(0)$24" [label = "join"]
"join_df(0)$0" -> "df1(0)$1" [label = "join"]
"join_df(0)$1" -> "join_df(0)$0" [label = "show"]
"df(0)$25" -> "df(0)$24" [label = "show"]
"pyspark.sql.window" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"Window" -> "pyspark.sql.window" [label = "importedBy"]
"Window(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"Window(0)" -> "Window" [label = "assignedFrom"]
"pyspark.sql.functions" -> "working-with-pyspark.ipynb" [label = "importedBy"]
"col" -> "pyspark.sql.functions" [label = "importedBy"]
"col(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"col(0)" -> "col" [label = "assignedFrom"]
"row_number" -> "pyspark.sql.functions" [label = "importedBy"]
"row_number(0)" -> "working-with-pyspark.ipynb" [label = "appearsIn"]
"row_number(0)" -> "row_number" [label = "assignedFrom"]
"WinF(0)$0" -> "Window(0)" [label = "orderBy"]
"WinF(0)$0" -> "df(0)$25" [label = "orderBy"]
"df(0)$26" -> "df(0)$25" [label = "withColumn"]
"df(0)$26" -> "row_number(0)" [label = "withColumn"]
"df(0)$26" -> "WinF(0)$0" [label = "withColumn"]
"df(0)$27" -> "df(0)$26" [label = "show"]
}